{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mselenium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwebdriver\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mby\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m By\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Initialize the Selenium driver\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m driver \u001B[38;5;241m=\u001B[39m \u001B[43mwebdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutable_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath_to_chromedriver\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Replace with the path to your chromedriver\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Open the website\u001B[39;00m\n\u001B[0;32m      8\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.cmegroup.com/trading/fx/cme-fx-options-vol-converter.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize the Selenium driver\n",
    "driver = webdriver.Chrome(executable_path='path_to_chromedriver')  # Replace with the path to your chromedriver\n",
    "\n",
    "# Open the website\n",
    "url = \"https://www.cmegroup.com/trading/fx/cme-fx-options-vol-converter.html\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Extract and print the article titles\n",
    "for title_element in article_title_elements:\n",
    "    title = title_element.text\n",
    "    print(title)\n",
    "\n",
    "# Close the Selenium driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"title-curve\">Japan Yield Curve</h2>\n",
      "<h2 id=\"title-analysis\">Japan Yield Analysis</h2>\n",
      "<h2 id=\"title-rating\">Japan Credit Ratings</h2>\n",
      "<h2 id=\"title-interest-rates\">Japan Interest Rates</h2>\n",
      "<h2 id=\"title-cds\">Japan Credit Default Swaps</h2>\n",
      "<h2 id=\"title-spread\">Japan 10Y Bond Yield Spread</h2>\n",
      "<h2 id=\"title-prices\">Japan Government Bonds Prices</h2>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.worldgovernmentbonds.com/country/japan/\"  # Replace with the URL of the website you want to scrape\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the HTML elements that contain the article titles\n",
    "    # You will need to inspect the website's HTML structure to find the right elements\n",
    "    article_elements = soup.find_all(\"h2\")  # Replace \"h2\" with the appropriate HTML tag\n",
    "\n",
    "    # Loop through the article elements and extract the titles\n",
    "    for article in article_elements:\n",
    "        title = article.text.strip()  # Get the text content and remove leading/trailing spaces\n",
    "        print(article)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "YC = article_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
