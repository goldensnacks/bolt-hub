{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "# FINANCEPY BETA Version 0.290 - This build:  10 May 2023 at 18:52 #\n",
      "#     This software is distributed FREE AND WITHOUT ANY WARRANTY   #\n",
      "#  Report bugs as issues at https://github.com/domokane/FinancePy  #\n",
      "####################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\financepy\\products\\equity\\equity_binomial_tree.py:36: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import Tradables\n",
    "reload(Tradables)\n",
    "from Tradables import Underlier\n",
    "import pickle\n",
    "import gs_quant\n",
    "from gs_quant.session import GsSession\n",
    "from datetime import datetime, timedelta\n",
    "import investpy\n",
    "from gs_quant.analytics.datagrid import DataColumn\n",
    "from gs_quant.analytics.processors import LastProcessor, EntityProcessor\n",
    "from gs_quant.data.coordinate import DataCoordinate, DataMeasure, DataFrequency\n",
    "from gs_quant.analytics.datagrid import DataRow\n",
    "from gs_quant.markets.securities import Asset, AssetIdentifier\n",
    "from gs_quant.analytics.datagrid import DataColumn, DataRow, DimensionsOverride, DataGrid\n",
    "from gs_quant.analytics.processors import LastProcessor, EntityProcessor, CoordinateProcessor\n",
    "from gs_quant.data import DataDimension\n",
    "from gs_quant.data.coordinate import DataCoordinate, DataMeasure, DataFrequency\n",
    "from gs_quant.markets.securities import AssetIdentifier, Asset\n",
    "from gs_quant.session import GsSession\n",
    "import pandas as pd\n",
    "import os\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\"\"\"import EURUSD data\"\"\"\n",
    "def save_security(sec):\n",
    "    \"\"\"save security to pickle in the securities folder\"\"\"\n",
    "    with open(f\"Securities/{sec.name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sec, f)\n",
    "GsSession.use(\n",
    "    client_id=\"3e871897e5474a0488cb09ea699ffe1c\",\n",
    "    client_secret=\"3dd2854652249d480cb7e8724ff23ee892dde030da367d24917565183b2ae929\"\n",
    ")\n",
    "date_offsets = {\n",
    "    '1D': timedelta(days=1),\n",
    "    '1W': timedelta(weeks=1),\n",
    "    '2W': timedelta(weeks=2),\n",
    "    '3W': timedelta(weeks=3),\n",
    "    '1M': timedelta(days=30),\n",
    "    '2M': timedelta(days=60),\n",
    "    '3M': timedelta(days=90),\n",
    "    '6M': timedelta(days=180),\n",
    "    '9M': timedelta(days=270),\n",
    "    '1Y': timedelta(days=365),\n",
    "    'Overnight': timedelta(days=1),\n",
    "    'Tomorrow Next': timedelta(days=1),\n",
    "    'Spot Next': timedelta(days=2),\n",
    "    'One Week': timedelta(weeks=1),\n",
    "    'Two Weeks': timedelta(weeks=2),\n",
    "    'Three Weeks': timedelta(weeks=3),\n",
    "    'One Month': timedelta(days=30),\n",
    "    'Two Months': timedelta(days=60),\n",
    "    'Three Months': timedelta(days=90),\n",
    "    'Four Months': timedelta(days=120),\n",
    "    'Five Months': timedelta(days=150),\n",
    "    'Six Months': timedelta(days=180),\n",
    "    'Seven Months': timedelta(days=210),\n",
    "    'Eight Months': timedelta(days=240),\n",
    "    'Nine Months': timedelta(days=270),\n",
    "    'Ten Months': timedelta(days=300),\n",
    "    'Eleven Months': timedelta(days=330),\n",
    "    'One Year': timedelta(days=365),\n",
    "    'Two Years': timedelta(days=730),\n",
    "    'Three Years': timedelta(days=1095),\n",
    "    'Four Years': timedelta(days=1460),\n",
    "    'Five Years': timedelta(days=1825),\n",
    "    'Six Years': timedelta(days=2190),\n",
    "    'Seven Years': timedelta(days=2555),\n",
    "    'Ten Years': timedelta(days=3650),\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"use excel wings to load surface from EURUSD Risk&Marks\"\"\"\n",
    "guipath = os.path.abspath('C:\\\\Users\\\\jacob\\\\bolt-hub\\\\GUI.xlsx')\n",
    "marks = pd.read_excel(guipath, sheet_name=\"EURUSD Risks&Marks\")\n",
    "\n",
    "\n",
    "\n",
    "def save_security(sec):\n",
    "    \"\"\"save security to pickle in the securities folder\"\"\"\n",
    "    with open(f\"Securities/{sec.name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sec, f)\n",
    "\n",
    "def get_intraday_weighting():\n",
    "    ticker_symbol = 'EURUSD=X'\n",
    "    start_date = '2022-01-01'\n",
    "    end_date = '2023-06-01'\n",
    "    # Get the data from Yahoo Finance\n",
    "    data = yf.download(ticker_symbol, start=start_date, end=end_date, interval=\"1h\")\n",
    "\n",
    "    # Extract the open and close prices by hour\n",
    "    hourly_data = data[['Open', 'Close']].resample('H').last()\n",
    "\n",
    "    \"\"\"create a column representing hour of the day\"\"\"\n",
    "    hourly_data['Hour'] = hourly_data.index.hour\n",
    "    \"\"\"create a column representing change in price from previous hour\"\"\"\n",
    "    hourly_data['Change'] = abs(hourly_data['Open']-hourly_data['Close'])/hourly_data['Open']\n",
    "\n",
    "    \"\"\"group by hour and calculate mean change\"\"\"\n",
    "    hourly_data = hourly_data.groupby('Hour')['Change'].mean()\n",
    "    return hourly_data\n",
    "\n",
    "def extract_forward_curve(marks):\n",
    "    \"\"\"extract forward curve\"\"\"\n",
    "    fwd = marks.drop(index=range(5))\n",
    "    last_row_index = fwd.index[-31]\n",
    "    # Select all rows up to and including the last 31st row, and assign it back to the dataframe\n",
    "    fwd = fwd.iloc[:last_row_index+1, :]\n",
    "    fwd = fwd.iloc[:, :4]\n",
    "    fwd.iloc[1:, 0] = [date_offsets[tenor] for tenor in fwd.iloc[1:, 0]]\n",
    "    # get the values of the top row as a series\n",
    "    new_columns = fwd.iloc[0]\n",
    "    # assign the new column names to the dataframe\n",
    "    fwd.columns = new_columns\n",
    "    # drop the first row since it's no longer needed as column names\n",
    "    fwd = fwd.iloc[1:]\n",
    "    # set the index to the values in the first column by position\n",
    "    fwd = fwd.set_index(fwd.columns[0])\n",
    "    # drop the first column since it's now the index\n",
    "    fwd = fwd.drop(columns=[fwd.columns[0]])\n",
    "    fwd = fwd.rename_axis(index=None).rename_axis(columns=None)\n",
    "    fwd.drop('Bid', axis=1, inplace=True)\n",
    "    return fwd\n",
    "\n",
    "def extract_vol_surface(marks):\n",
    "    \"\"\"extract vol surface\"\"\"\n",
    "    vols = marks.drop(index=range(33))\n",
    "    vols = vols.iloc[0:, :18]\n",
    "    # get the values of the top row as a series\n",
    "    new_columns = [5,10,15,20,25,30,35,40,45,50,-40,-35,-30,-25,-20,-15,-10,-5]\n",
    "    # assign the new column names to the dataframe\n",
    "    vols.columns = new_columns\n",
    "    # drop the first row since it's no longer needed as column names\n",
    "    vols = vols.iloc[1:]\n",
    "    # set the index to the values in the first column by position\n",
    "    vols = vols.set_index(vols.columns[0])\n",
    "    # drop the first column since it's now the index\n",
    "    vols = vols.drop(columns=[vols.columns[0]])\n",
    "    vols = vols.rename_axis(index=None).rename_axis(columns=None)\n",
    "    new_index = [date_offsets[tenor] for tenor in vols.index]\n",
    "    vols.set_index(pd.Index(new_index), inplace=True)\n",
    "    return vols\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "eurusd = Underlier(\"EURUSD\")\n",
    "eurusd.load_forward_curve(extract_forward_curve(marks))\n",
    "eurusd.load_vol_surface(extract_vol_surface(marks))\n",
    "eurusd.mark_spot(1.0935)\n",
    "eurusd.load_intraday_weights(get_intraday_weighting())\n",
    "\n",
    "save_security(eurusd)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "array(1.09933)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"load eurusd from pickle\"\"\"\n",
    "with open(\"Securities/EURUSD.pkl\", \"rb\") as f:\n",
    "    eurusd = pickle.load(f)\n",
    "\n",
    "eurusd.forward_curve_as_fn()(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
